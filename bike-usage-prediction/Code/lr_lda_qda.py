# -*- coding: utf-8 -*-
"""LR_LDA_QDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ibXm4k3Qquw-Tr3GUw_a5_ySPEs9YDJF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegressionCV
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.metrics import precision_recall_curve, f1_score
from sklearn.metrics import roc_curve, roc_auc_score
import math as mt

#data import and cleaning
data = pd.read_csv("training_data_fall2024.csv")
data=data.drop(['snow', 'summertime'], axis = 1)

#80:10:10 split
X = data[['hour_of_day','day_of_week','month'
          ,'holiday','weekday','temp','dew',
          'humidity','precip','snowdepth',
          'windspeed','cloudcover','visibility']]
Y = data['increase_stock']
X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y,
                                                  test_size=0.1,
                                                  random_state=42)
X_train, X_valid, Y_train, Y_valid = train_test_split(X_temp, Y_temp,
                                                      test_size=0.111,
                                                      random_state=42)

#standardization (leads to higher accuracies accross the board)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_valid = scaler.fit_transform(X_valid)
X_test = scaler.fit_transform(X_test)

treshold = 0.5

#logistic regression model hyperparameter grid search tuning
#errors in output caused by incompatible solvers and penalties
from sklearn.model_selection import GridSearchCV

param_grid = {
    'penalty':['l1','l2','elasticnet'],
    'C' : np.logspace(-4,4,20),
    'solver': ['lbfgs','newton-cg','liblinear','sag','saga'],
    'max_iter'  : [3000,5000]
}

grid_search = GridSearchCV(
    estimator=LogisticRegression(random_state=42),
    param_grid=param_grid,
    cv=5,  # 5-fold cross-validation
    n_jobs=-1,  # Use all available processors
    verbose=1
)

grid_search.fit(X_train, Y_train)
Y_pred = grid_search.predict(X_valid)

print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

#logistic regression model
#liblinear came out to be the best solver as expected
#since it is a small dataset
#max_iter is set to 3000 to avoid the ConvergenceWarning
model = LogisticRegression(random_state=42, max_iter=3000,
                           penalty='l1', solver='liblinear',
                           C=0.23357214690901212)
model.fit(X_train,Y_train)
print(model)

train_predict = model.predict_proba(X_train)
prediction = np.empty(len(X_train),dtype=object)
prediction = np.where(train_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print("Train Accuracy:",f"{np.mean(prediction == Y_train):.3f}")

test_predict = model.predict_proba(X_test)
prediction = np.empty(len(X_test),dtype=object)
prediction = np.where(test_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print(pd.crosstab(prediction,Y_test))
# print(f"{f1_scores[best_index]:.2f}")
print("Test Accuracy:",f"{np.mean(prediction == Y_test):.3f}")

model = LogisticRegression(random_state=42, max_iter=3000,
                           penalty='l1', solver='liblinear',
                           C=0.23357214690901212)
model.fit(X_train,Y_train)
train_predict = model.predict_proba(X_train)[:,1]
Y_train=Y_train.replace(to_replace="low_bike_demand",value=0)
Y_train=Y_train.replace(to_replace="high_bike_demand",value=1)

precision, recall, thresholds = precision_recall_curve(Y_train,
                                                       train_predict)

f1_scores = 2 * (precision * recall) / (precision + recall)
f1_scores = np.nan_to_num(f1_scores)  # Handle division by zero

best_index = np.argmax(f1_scores)
best_threshold = thresholds[best_index]

print(f"Best Threshold: {best_threshold}")
print(f"Precision: {precision[best_index]:.2f}")
print(f"Recall: {recall[best_index]:.2f}")
print(f"F1 Score: {f1_scores[best_index]:.2f}")

y_pred_thresholded = (train_predict >= best_threshold).astype(int)

from sklearn.metrics import classification_report
print(classification_report(Y_train, y_pred_thresholded))

#LDA hyperparameter grid search tuning
#errors in output caused by incompatible solvers and penalties
from sklearn.model_selection import GridSearchCV

param_grid = {
    'shrinkage': [None, 'auto'] + [x / 10 for x in range(0, 11)],
    'solver': ['svd', 'lsqr', 'eigen'],
    'store_covariance': [True, False]
}

grid_search = GridSearchCV(
    estimator=LinearDiscriminantAnalysis(),
    param_grid=param_grid,
    cv=5,  # 5-fold cross-validation
    n_jobs=-1,  # Use all available processors
    verbose=1
)

grid_search.fit(X_train, Y_train)
Y_pred = grid_search.predict(X_valid)

print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

#LDA
lda_model = LinearDiscriminantAnalysis(shrinkage='auto',
                                   solver='lsqr',
                                   store_covariance=True)
lda_model.fit(X_train,Y_train)
print(lda_model)
lda_train_predict = lda_model.predict_proba(X_train)
lda_prediction = np.empty(len(X_train),dtype=object)
lda_prediction = np.where(lda_train_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print("Train Accuracy:",f"{np.mean(lda_prediction == Y_train):.3f}")

lda_test_predict = lda_model.predict_proba(X_test)
lda_prediction = np.empty(len(X_test),dtype=object)
lda_prediction = np.where(lda_test_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print(pd.crosstab(lda_prediction,Y_test))
print("Test Accuracy:",f"{np.mean(lda_prediction == Y_test):.3f}")

Y_train=Y_train.replace(to_replace="low_bike_demand",value=0)
Y_train=Y_train.replace(to_replace="high_bike_demand",value=1)
from sklearn.metrics import classification_report
print(classification_report(Y_train, y_pred_thresholded))

#QDA hyperparameter grid search tuning
#To avoid problems due to the variables being collinear
#we use PCA to decompose data as suggested here:
#https://mevik.net/work/publications/understanding_collinearity.pdf
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_valid_pca = pca.fit_transform(X_valid)
X_test_pca = pca.fit_transform(X_test)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5,
                  0.6, 0.7, 0.8, 0.9, 0.95, 1],
    'store_covariance': [True, False]
}

grid_search = GridSearchCV(
    estimator=QuadraticDiscriminantAnalysis(),
    param_grid=param_grid,
    cv=5,  # 5-fold cross-validation
    n_jobs=-1,  # Use all available processors
    verbose=1
)

grid_search.fit(X_train_pca, Y_train)
Y_pred = grid_search.predict(X_valid_pca)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

#QDA
qda_model = QuadraticDiscriminantAnalysis(reg_param=0.9,
                                      store_covariance=True)
qda_model.fit(X_train_pca,Y_train)
print(qda_model)
qda_train_predict = qda_model.predict_proba(X_train_pca)
qda_prediction = np.empty(len(X_train_pca),dtype=object)
qda_prediction = np.where(qda_train_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print("Train Accuracy:",f"{np.mean(qda_prediction == Y_train):.3f}")

qda_test_predict = qda_model.predict_proba(X_test_pca)
qda_prediction = np.empty(len(X_test_pca),dtype=object)
qda_prediction = np.where(qda_test_predict[:,0]>=treshold,
                      'high_bike_demand','low_bike_demand')
print(pd.crosstab(qda_prediction,Y_test))
print("Test Accuracy:",f"{np.mean(qda_prediction == Y_test):.3f}")

Y_train=Y_train.replace(to_replace="low_bike_demand",value=0)
Y_train=Y_train.replace(to_replace="high_bike_demand",value=1)
from sklearn.metrics import classification_report
print(classification_report(Y_train, y_pred_thresholded))
